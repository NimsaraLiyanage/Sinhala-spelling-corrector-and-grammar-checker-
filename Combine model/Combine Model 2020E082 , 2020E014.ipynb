{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdiT3GaQiZDa"
      },
      "source": [
        "Step 1: Import Required Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URDnja6qdAPN",
        "outputId": "69586dd4-c4a9-4745-f10e-0461adc19243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK tokenizer\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LunCDdz_ifkE"
      },
      "source": [
        "Step 2: Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NueuS5SPihQz",
        "outputId": "73ffec40-d20c-4ac0-d0e0-0990eaa380a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 16930,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16930,\n        \"samples\": [\n          \"\\u0db8\\u0db8 \\u0db1\\u0dd0\\u0da7\\u0dd4\\u0db8\\u0dca \\u0db1\\u0da7\\u0daf\\u0dca\\u0daf\\u0dd3 \\u0dc0\\u0dcf\\u0dc4\\u0db1 \\u0d94\\u0dc4\\u0dd4\\u0d9c\\u0dd9\\u0db1\\u0dca \\u0db4\\u0ddc\\u0dad\\u0d9a\\u0dca \\u0d9c\\u0db1\\u0dca\\u0db1\\u0dd9\\u0dc4\\u0dd2\\u0dc0\\u0dcf\",\n          \"\\u0d94\\u0db6 \\u0dc3\\u0dd2\\u0db1\\u0dca\\u0daf\\u0dd4 \\u0d9a\\u0dd2\\u0dc0\\u0dca\\u0dc0\\u0ddc\\u0dad\\u0dca \\u0d85\\u0db4\\u0dd2 \\u0d9c\\u0dd9\\u0daf\\u0dbb \\u0dc0\\u0dda\\u0d9c\\u0dba\\u0dd9\\u0db1\\u0dca \\u0dba\\u0dc0\\u0db1\\u0dca\\u0db1\\u0ddd\\u0dba\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-44501e59-6ec2-4225-a6c4-aa8c3e506f3a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>මම යති</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>මම යත්වා</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>මම යනවා</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>මම යනවාලා</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>මම යනු</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44501e59-6ec2-4225-a6c4-aa8c3e506f3a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44501e59-6ec2-4225-a6c4-aa8c3e506f3a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44501e59-6ec2-4225-a6c4-aa8c3e506f3a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13d8d1cc-6e9f-4505-beac-942b6394b4ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13d8d1cc-6e9f-4505-beac-942b6394b4ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13d8d1cc-6e9f-4505-beac-942b6394b4ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   label   sentence\n",
              "0      0     මම යති\n",
              "1      0   මම යත්වා\n",
              "2      0    මම යනවා\n",
              "3      0  මම යනවාලා\n",
              "4      0     මම යනු"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load test data with UTF-16 encoding\n",
        "test_data_path = '/content/test_dataset.txt'\n",
        "\n",
        "with open(test_data_path, 'r', encoding='utf-16') as file:\n",
        "    sentences = [line.strip().split(\" \", 1) for line in file.readlines()]\n",
        "\n",
        "# Process the sentences and load into DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(sentences, columns=[\"label\", \"sentence\"])\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "# Check the first few rows of the dataframe to ensure it's loaded correctly\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnYLNpmTi08O"
      },
      "source": [
        "Step 3: Handle Missing Values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbOPLqTGiy_3",
        "outputId": "6e60bdf3-6468-4ca3-9380-c1f7ebf3225e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values handled. Dataset preview:\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values and handle them\n",
        "df['sentence'] = df['sentence'].fillna('')  # Replace NaN with an empty string\n",
        "\n",
        "# Optional: Drop rows with missing sentences if needed\n",
        "# df = df.dropna(subset=['sentence'])\n",
        "\n",
        "print(\"Missing values handled. Dataset preview:\")\n",
        "print(df.isnull().sum())  # Verify no missing values remain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEtd8RmAi87c"
      },
      "source": [
        "Step 4: Split Data into Features and Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSy2bbn_i6ox",
        "outputId": "06bc80af-354a-4b69-865e-b51fef2f23f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train-test split completed.\n",
            "Training samples: 13544, Testing samples: 3386\n"
          ]
        }
      ],
      "source": [
        "# Split data into sentences (features) and labels (target)\n",
        "X = df['sentence']  # Features: sentences\n",
        "y = df['label']     # Labels: 1 (correct), 0 (incorrect)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train-test split completed.\")\n",
        "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPwVyDxOjE5r"
      },
      "source": [
        "Step 5: Text Vectorization Using CountVectorizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4pXPdFrjEei",
        "outputId": "cf7d68ff-19fc-4797-8d01-9ff46150f088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorization completed. Feature matrix size:\n",
            "Training data: (13544, 221), Testing data: (3386, 221)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "# Download the required NLTK data package\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Initialize CountVectorizer with a custom tokenizer\n",
        "vectorizer = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
        "\n",
        "# Convert text data into numeric vectors\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Vectorization completed. Feature matrix size:\")\n",
        "print(f\"Training data: {X_train_vectorized.shape}, Testing data: {X_test_vectorized.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNlazOR_jajJ"
      },
      "source": [
        "Step 6: Train the Random Forest Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYaxwqLkjcN-",
        "outputId": "45b992b9-6ab0-4fff-fd5c-53ed95ac0f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training completed.\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the vectorized training data\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Model training completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHwlIPuDji8c"
      },
      "source": [
        "Step 7: Evaluate the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndwUy-iXjiiE",
        "outputId": "4c009bd4-ec04-4715-b5b4-7e9252c37af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdd5z6HRjoST"
      },
      "source": [
        "Step 8: Predict and Correct Sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLcXbRDojqlq",
        "outputId": "15bcb2ea-1e66-424b-e9a3-cd16251c4240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Sentence: මම යනවා\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: (Correction logic required)\n"
          ]
        }
      ],
      "source": [
        "# Define a function to predict and correct sentences\n",
        "def grammar_checker(sentence):\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Suggest a correction (mock correction here for demonstration)\n",
        "        # In practice, this could involve further analysis\n",
        "        print(\"Correct Sentence: (Correction logic required)\")\n",
        "\n",
        "# Test the function with a sample sentence\n",
        "sample_sentence = \"මම යනවා\"\n",
        "grammar_checker(sample_sentence)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df0BKzx2kxrX"
      },
      "source": [
        "Final Pipeline Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w4Iz3SK6kuaS"
      },
      "outputs": [],
      "source": [
        "def grammar_checker(sentence, vectorizer, model, df):\n",
        "    \"\"\"\n",
        "    Check the grammar of a sentence and suggest a correction if it's incorrect.\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: The input sentence to check.\n",
        "    - vectorizer: The trained CountVectorizer.\n",
        "    - model: The trained classification model.\n",
        "    - df: The original dataset (used to find corrections).\n",
        "    \"\"\"\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Find a similar correct sentence from the dataset\n",
        "        correct_sentences = df[df['label'] == 1]['sentence']\n",
        "        most_similar = None\n",
        "        max_similarity = 0\n",
        "\n",
        "        for correct_sentence in correct_sentences:\n",
        "            # Calculate similarity between input and dataset sentences\n",
        "            similarity = len(set(sentence.split()).intersection(set(correct_sentence.split())))\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar = correct_sentence\n",
        "\n",
        "        if most_similar:\n",
        "            print(f\"Correct Sentence: {most_similar}\")\n",
        "        else:\n",
        "            print(\"Correct Sentence: No suggestion found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzI4C4XyVXQI",
        "outputId": "9a2f9b04-67ed-4388-bd6f-802e85f04d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: අපි යැවෙමු\n",
            "Sentence is Correct.\n",
            "\n",
            "\n",
            "Input Sentence: මම ගියෙමි\n",
            "Sentence is Correct.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = [\"අපි යැවෙමු\", \"මම ගියෙමි\"]\n",
        "for sentence in sentences:\n",
        "    grammar_checker(sentence, vectorizer, model, df)\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4jeh_v6fY-3"
      },
      "source": [
        "Experiment with Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Slr2I1gW2jl",
        "outputId": "a987a0bd-cc35-40bb-810a-2024c542e876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "best_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oVXLF-AfaAT"
      },
      "source": [
        "Evaluate Using Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH6T3C9aY69J",
        "outputId": "f31e9518-bd6a-4c4e-aecd-f3f441d64d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy: 0.95\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X_train_vectorized, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy: {scores.mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1Bncnehffwn"
      },
      "source": [
        "Update Grammar Checker for Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH8vuoYIZGBT",
        "outputId": "a35149c0-26fe-4c15-854c-d84daeb4b93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: මම යනවා -> Incorrect\n",
            "Sentence: මම යත්වා -> Incorrect\n",
            "Sentence: මම ගියෙමි -> Correct\n"
          ]
        }
      ],
      "source": [
        "def grammar_checker(sentence, vectorizer, model):\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "    return \"Correct\" if prediction == 1 else \"Incorrect\"\n",
        "\n",
        "sentences = [\"මම යනවා\", \"මම යත්වා\", \"මම ගියෙමි\"]\n",
        "for sentence in sentences:\n",
        "    result = grammar_checker(sentence, vectorizer, best_model)\n",
        "    print(f\"Sentence: {sentence} -> {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O19c33lfiZ2"
      },
      "source": [
        "Use Confusion Matrix for Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHzuyVG2ZMaP",
        "outputId": "9bb8c4c7-600e-426b-881c-57fc13e5ea6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2855    0]\n",
            " [ 130  401]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      2855\n",
            "           1       1.00      0.76      0.86       531\n",
            "\n",
            "    accuracy                           0.96      3386\n",
            "   macro avg       0.98      0.88      0.92      3386\n",
            "weighted avg       0.96      0.96      0.96      3386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "y_test_pred = model.predict(X_test_vectorized)\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsyGWsq5a346",
        "outputId": "9d2d0e0f-bbb9-406b-e43b-7793963dee77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: අපි යනු -> Incorrect\n",
            "Sentence: අපි යමු -> Correct\n",
            "Sentence: අපි යවමි -> Incorrect\n"
          ]
        }
      ],
      "source": [
        "sentences = [\"අපි යනු\", \"අපි යමු\", \"අපි යවමි\"]\n",
        "for sentence in sentences:\n",
        "    result = grammar_checker(sentence, vectorizer, best_model)\n",
        "    print(f\"Sentence: {sentence} -> {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFeru9AQbIls",
        "outputId": "50713641-d4b1-462a-bd2d-46e2bbe09783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: අපි යනු\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: අපි යන්නෙමු\n",
            "\n",
            "\n",
            "Input Sentence: අපි යමු\n",
            "Sentence is Correct.\n",
            "\n",
            "\n",
            "Input Sentence: අපි යවමි\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: මම යවමි\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def grammar_checker(sentence, vectorizer, model, df):\n",
        "\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Find a similar correct sentence from the dataset\n",
        "        correct_sentences = df[df['label'] == 1]['sentence']\n",
        "        most_similar = None\n",
        "        max_similarity = 0\n",
        "\n",
        "        for correct_sentence in correct_sentences:\n",
        "            # Calculate similarity between input and dataset sentences\n",
        "            # Using Jaccard similarity for better results\n",
        "            set1 = set(sentence.split())\n",
        "            set2 = set(correct_sentence.split())\n",
        "            similarity = len(set1.intersection(set2)) / len(set1.union(set2)) if set1.union(set2) else 0\n",
        "\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar = correct_sentence\n",
        "\n",
        "        if most_similar:\n",
        "            print(f\"Correct Sentence: {most_similar}\")\n",
        "        else:\n",
        "            print(\"Correct Sentence: No suggestion found.\")\n",
        "\n",
        "\n",
        "# Example usage (assuming you have vectorizer, model, and df defined)\n",
        "# Replace with your actual vectorizer, model and DataFrame\n",
        "sentences = [\"අපි යනු\", \"අපි යමු\", \"අපි යවමි\"]\n",
        "for sentence in sentences:\n",
        "    grammar_checker(sentence, vectorizer, best_model, df)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gkk4LisbhmW",
        "outputId": "22e1dd87-623b-4910-97b9-32bd263e2266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence: මම ඔහුගෙන් පොතක් ගත්තෙමි\n",
            "Sentence is Correct.\n",
            "\n",
            "\n",
            "Input Sentence: නුබ ගියෙහි\n",
            "Sentence is Correct.\n",
            "\n",
            "\n",
            "Input Sentence: ළමයි වේගයෙන් ගියෝය\n",
            "Sentence is Correct.\n",
            "\n",
            "\n",
            "Input Sentence:  මම ගෙදර යමු\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: මම ගෙදර යන්නෙමි\n",
            "\n",
            "\n",
            "Input Sentence: නුබලා ගෙදර වේගයෙන් ගියෙහි\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: නුබ ගෙදර වේගයෙන් ගියෙහි\n",
            "\n",
            "\n",
            "Input Sentence: ළමයා පොත බලා ගෙදර ගියෙහු\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: නුබලා පොත බලා ගෙදර ගියෙහු\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = [\"මම ඔහුගෙන් පොතක් ගත්තෙමි\", \"නුබ ගියෙහි\", \"ළමයි වේගයෙන් ගියෝය\" , \" මම ගෙදර යමු\", \"නුබලා ගෙදර වේගයෙන් ගියෙහි\",\"ළමයා පොත බලා ගෙදර ගියෙහු\"]\n",
        "for sentence in sentences:\n",
        "    grammar_checker(sentence, vectorizer, best_model, df)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ed7Y1-O1kO35"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming 'model', 'vectorizer', and 'df' are defined as in the provided code\n",
        "\n",
        "# Save the model\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Save the vectorizer\n",
        "with open('vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(vectorizer, f)\n",
        "\n",
        "# Save the DataFrame (optional, depending on your needs)\n",
        "df.to_pickle('df.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W04KrX1-ckr0",
        "outputId": "4b506240-7caa-4631-b386-ff8adfcf352a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled. Dataset preview:\n",
            "label       0\n",
            "sentence    0\n",
            "dtype: int64\n",
            "Train-test split completed.\n",
            "Training samples: 13544, Testing samples: 3386\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Vectorization completed. Feature matrix size:\n",
            "Training data: (13544, 221), Testing data: (3386, 221)\n",
            "Model training completed.\n",
            "Model Accuracy: 0.96\n",
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "Cross-Validation Accuracy: 0.95\n",
            "[[2855    0]\n",
            " [ 130  401]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98      2855\n",
            "           1       1.00      0.76      0.86       531\n",
            "\n",
            "    accuracy                           0.96      3386\n",
            "   macro avg       0.98      0.88      0.92      3386\n",
            "weighted avg       0.96      0.96      0.96      3386\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "# Step 1: Import Required Libraries\n",
        "#\n",
        "#\n",
        "\n",
        "# Download required NLTK tokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Step 2: Load the Dataset\n",
        "# Load test data with UTF-16 encoding\n",
        "test_data_path = '/content/test_dataset.txt'\n",
        "\n",
        "with open(test_data_path, 'r', encoding='utf-16') as file:\n",
        "    sentences = [line.strip().split(\" \", 1) for line in file.readlines()]\n",
        "\n",
        "# Process the sentences and load into DataFrame\n",
        "\n",
        "df = pd.DataFrame(sentences, columns=[\"label\", \"sentence\"])\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "# Check the first few rows of the dataframe to ensure it's loaded correctly\n",
        "df.head()\n",
        "# Step 3: Handle Missing Values\n",
        "#\n",
        "# Check for missing values and handle them\n",
        "df['sentence'] = df['sentence'].fillna('')  # Replace NaN with an empty string\n",
        "\n",
        "# Optional: Drop rows with missing sentences if needed\n",
        "# df = df.dropna(subset=['sentence'])\n",
        "\n",
        "print(\"Missing values handled. Dataset preview:\")\n",
        "print(df.isnull().sum())  # Verify no missing values remain\n",
        "\n",
        "# Step 4: Split Data into Features and Labels\n",
        "#\n",
        "# Split data into sentences (features) and labels (target)\n",
        "X = df['sentence']  # Features: sentences\n",
        "y = df['label']     # Labels: 1 (correct), 0 (incorrect)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train-test split completed.\")\n",
        "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n",
        "\n",
        "# Step 5: Text Vectorization Using CountVectorizer\n",
        "#\n",
        "#\n",
        "!pip install nltk\n",
        "\n",
        "# Initialize CountVectorizer with a custom tokenizer\n",
        "vectorizer = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
        "\n",
        "# Convert text data into numeric vectors\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Vectorization completed. Feature matrix size:\")\n",
        "print(f\"Training data: {X_train_vectorized.shape}, Testing data: {X_test_vectorized.shape}\")\n",
        "# Step 6: Train the Random Forest Classifier\n",
        "#\n",
        "# Initialize the Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the vectorized training data\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Model training completed.\")\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "#\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Calculate and display accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Step 8: Predict and Correct Sentences\n",
        "#\n",
        "# Define a function to predict and correct sentences\n",
        "def grammar_checker(sentence):\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Suggest a correction (mock correction here for demonstration)\n",
        "        # In practice, this could involve further analysis\n",
        "        print(\"Correct Sentence: (Correction logic required)\")\n",
        "\n",
        "# Final Pipeline Code\n",
        "\n",
        "def grammar_checker(sentence, vectorizer, model, df):\n",
        "    \"\"\"\n",
        "    Check the grammar of a sentence and suggest a correction if it's incorrect.\n",
        "\n",
        "    Parameters:\n",
        "    - sentence: The input sentence to check.\n",
        "    - vectorizer: The trained CountVectorizer.\n",
        "    - model: The trained classification model.\n",
        "    - df: The original dataset (used to find corrections).\n",
        "    \"\"\"\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Find a similar correct sentence from the dataset\n",
        "        correct_sentences = df[df['label'] == 1]['sentence']\n",
        "        most_similar = None\n",
        "        max_similarity = 0\n",
        "\n",
        "        for correct_sentence in correct_sentences:\n",
        "            # Calculate similarity between input and dataset sentences\n",
        "            similarity = len(set(sentence.split()).intersection(set(correct_sentence.split())))\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar = correct_sentence\n",
        "\n",
        "        if most_similar:\n",
        "            print(f\"Correct Sentence: {most_similar}\")\n",
        "        else:\n",
        "            print(\"Correct Sentence: No suggestion found.\")\n",
        "\n",
        "# Experiment with Hyperparameter Tuning\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate Using Cross-Validation\n",
        "\n",
        "scores = cross_val_score(model, X_train_vectorized, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy: {scores.mean():.2f}\")\n",
        "\n",
        "# Update Grammar Checker for Accuracy\n",
        "def grammar_checker(sentence, vectorizer, model):\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "    return \"Correct\" if prediction == 1 else \"Incorrect\"\n",
        "\n",
        "# Use Confusion Matrix for Insights\n",
        "\n",
        "y_test_pred = model.predict(X_test_vectorized)\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "def grammar_checker(sentence, vectorizer, model, df):\n",
        "\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXT0QBy-h4wE",
        "outputId": "ebe6cb30-64ee-4b7f-987e-8da6f02d5ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence (or type 'exit' to quit): අම්මා යුහුෂුලුව අවදිවෙනවා\n",
            "Input Sentence: අම්මා යුහුෂුලුව අවදිවෙනවා\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: අම්මා යුහුසුලුව අවදිවූවාය\n",
            "\n",
            "\n",
            "Enter a sentence (or type 'exit' to quit): උකුෂ්ෂා සාර්ථඛව සුනඛයකු පස්සේ එළවනවා\n",
            "Input Sentence: උකුෂ්ෂා සාර්ථඛව සුනඛයකු පස්සේ එළවනවා\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: උකුස්සා සාර්ථකව සුනඛයකු පස්සේ එළවයි\n",
            "\n",
            "\n",
            "Enter a sentence (or type 'exit' to quit): සමකාළීන වෙඩික්කාරයා වෙඩිතියනවා\n",
            "Input Sentence: සමකාළීන වෙඩික්කාරයා වෙඩිතියනවා\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: සමකාලීන වෙඩික්කාරයා වෙඩිතිබ්බේය\n",
            "\n",
            "\n",
            "Enter a sentence (or type 'exit' to quit): ණාවිකයා සම්මත තාක්සණය නෞඛා පැදවීමට භාවිතා කරනවා\n",
            "Input Sentence: ණාවිකයා සම්මත තාක්සණය නෞඛා පැදවීමට භාවිතා කරනවා\n",
            "Sentence is Incorrect.\n",
            "Correct Sentence: නාවිකයා සම්මත තාක්ෂණය නෞකා පැදවීමට භාවිතා කළේය\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def grammar_checker(sentence, vectorizer, model, df):\n",
        "    # Vectorize the input sentence\n",
        "    vectorized_sentence = vectorizer.transform([sentence])\n",
        "\n",
        "    # Predict whether the sentence is correct or incorrect\n",
        "    prediction = model.predict(vectorized_sentence)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Correct.\")\n",
        "    else:\n",
        "        print(f\"Input Sentence: {sentence}\")\n",
        "        print(\"Sentence is Incorrect.\")\n",
        "\n",
        "        # Find a similar correct sentence from the dataset\n",
        "        correct_sentences = df[df['label'] == 1]['sentence']\n",
        "        most_similar = None\n",
        "        max_similarity = 0\n",
        "\n",
        "        for correct_sentence in correct_sentences:\n",
        "            # Calculate Jaccard similarity between input and dataset sentences\n",
        "            set1 = set(sentence.split())\n",
        "            set2 = set(correct_sentence.split())\n",
        "            similarity = len(set1.intersection(set2)) / len(set1.union(set2)) if set1.union(set2) else 0\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar = correct_sentence\n",
        "\n",
        "        if most_similar:\n",
        "             print(f\"Correct Sentence: {most_similar}\")\n",
        "        else:\n",
        "            print(\"Correct Sentence: No suggestion found.\")\n",
        "\n",
        "while True:\n",
        "    sentence = input(\"Enter a sentence (or type 'exit' to quit): \")\n",
        "    if sentence.lower() == 'exit':\n",
        "        break\n",
        "    grammar_checker(sentence, vectorizer, model, df)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}