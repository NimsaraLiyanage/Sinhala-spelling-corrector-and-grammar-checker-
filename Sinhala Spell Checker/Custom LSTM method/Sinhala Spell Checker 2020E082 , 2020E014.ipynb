{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QufM_FeebwZK"
      },
      "source": [
        "Step 1: Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-wEJkxK7FX1",
        "outputId": "1998ed77-04c0-4e13-ad86-4d18caa0f103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZqrt42qbpsz"
      },
      "source": [
        "Step 2: Load and Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wqzb06rE764z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/content/data-spell-checker.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Preprocess data\n",
        "data = data.dropna()  # Remove missing values\n",
        "words = data['word'].values\n",
        "labels = data['label'].values  # 1 for correct, 0 for incorrect\n",
        "\n",
        "# Tokenize the words\n",
        "tokenizer = Tokenizer(char_level=True)  # Tokenize at character level\n",
        "tokenizer.fit_on_texts(words)\n",
        "sequences = tokenizer.texts_to_sequences(words)\n",
        "\n",
        "# Pad sequences\n",
        "max_len = max(len(seq) for seq in sequences)  # Set max length to the longest word\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "y = to_categorical(labels, num_classes=2)  # Convert labels to one-hot encoding\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8-RxpswbeQk"
      },
      "source": [
        "Step 3: Define and Train the LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl84qL86AHXl",
        "outputId": "c080a2d4-5c2e-40ca-8097-8e4d070ea031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2553/2553 - 178s - 70ms/step - accuracy: 0.7614 - loss: 0.5179 - val_accuracy: 0.8374 - val_loss: 0.3868\n",
            "Epoch 2/10\n",
            "2553/2553 - 204s - 80ms/step - accuracy: 0.8619 - loss: 0.3589 - val_accuracy: 0.8767 - val_loss: 0.3339\n",
            "Epoch 3/10\n",
            "2553/2553 - 205s - 80ms/step - accuracy: 0.8789 - loss: 0.3104 - val_accuracy: 0.8859 - val_loss: 0.2843\n",
            "Epoch 4/10\n",
            "2553/2553 - 174s - 68ms/step - accuracy: 0.8917 - loss: 0.2674 - val_accuracy: 0.9028 - val_loss: 0.2381\n",
            "Epoch 5/10\n",
            "2553/2553 - 200s - 78ms/step - accuracy: 0.9120 - loss: 0.2175 - val_accuracy: 0.9172 - val_loss: 0.2131\n",
            "Epoch 6/10\n",
            "2553/2553 - 174s - 68ms/step - accuracy: 0.9264 - loss: 0.1846 - val_accuracy: 0.9300 - val_loss: 0.1781\n",
            "Epoch 7/10\n",
            "2553/2553 - 248s - 97ms/step - accuracy: 0.9357 - loss: 0.1630 - val_accuracy: 0.9362 - val_loss: 0.1638\n",
            "Epoch 8/10\n",
            "2553/2553 - 213s - 83ms/step - accuracy: 0.9432 - loss: 0.1465 - val_accuracy: 0.9411 - val_loss: 0.1559\n",
            "Epoch 9/10\n",
            "2553/2553 - 197s - 77ms/step - accuracy: 0.9497 - loss: 0.1319 - val_accuracy: 0.9452 - val_loss: 0.1451\n",
            "Epoch 10/10\n",
            "2553/2553 - 209s - 82ms/step - accuracy: 0.9546 - loss: 0.1199 - val_accuracy: 0.9470 - val_loss: 0.1431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_len),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # Binary classification: correct (1) or incorrect (0)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=32,\n",
        "    epochs=10,  # Adjust epochs for better performance\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/sinhala_spell_checker.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgSBHfxamwK"
      },
      "source": [
        "Step 4: Display Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGshVGmIIoY6",
        "outputId": "e89f3ed4-0daf-4b94-8a67-cbeb4a497d4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Sample Sentence 1:\n",
            "Original Sentence: අම්මා යුහුෂුලුව අවදිවෙනවා\n",
            "Misspelled Words: ['යුහුෂුලුව']\n",
            "Corrected Sentence: අම්මා යුහුසුලුව අවදිවෙනවා\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Sample Sentence 2:\n",
            "Original Sentence: උකුෂ්ෂා සාර්ථඛව සුනඛයකු පස්සේ එළවනවා\n",
            "Misspelled Words: ['උකුෂ්ෂා', 'සාර්ථඛව']\n",
            "Corrected Sentence: උකුස්සා සාර්ථකව සුනඛයකු පස්සේ එළවනවා\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Sample Sentence 3:\n",
            "Original Sentence: සමකාළීන වෙඩික්කාරයා වෙඩිතියනවා\n",
            "Misspelled Words: ['සමකාළීන']\n",
            "Corrected Sentence: සමකාලීන වෙඩික්කාරයා වෙඩිතියනවා\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Sample Sentence 4:\n",
            "Original Sentence: මුරඛාරයා සැළකිළිමත්ව වීදිය පසුකරනවා\n",
            "Misspelled Words: ['මුරඛාරයා', 'සැළකිළිමත්ව']\n",
            "Corrected Sentence: මුරකාරයා සැළකිලිමත්ව වීදිය පසුකරනවා\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Sample Sentence 5:\n",
            "Original Sentence: ණාවිකයා සම්මත තාක්සණය නෞඛා පැදවීමට භාවිතා කරනවා\n",
            "Misspelled Words: ['ණාවිකයා', 'තාක්සණය', 'නෞඛා']\n",
            "Corrected Sentence: නාවිකයා සම්මත තාක්ෂණය නෞකා පැදවීමට භාවිතා කරනවා\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from difflib import get_close_matches\n",
        "\n",
        "# Function to predict if a word is correct or incorrect\n",
        "def predict_word(word):\n",
        "    seq = tokenizer.texts_to_sequences([word])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "    pred = model.predict(padded_seq)\n",
        "    return np.argmax(pred)  # 0 = Incorrect, 1 = Correct\n",
        "\n",
        "# Function to correct misspelled words\n",
        "def auto_correct(word, correct_words):\n",
        "    if predict_word(word) == 1:\n",
        "        return word  # Word is correct\n",
        "    close_matches = get_close_matches(word, correct_words, n=1, cutoff=0.7)\n",
        "    return close_matches[0] if close_matches else word\n",
        "\n",
        "# Correct a sentence and display output in the desired format\n",
        "def process_sentence(sentence, sample_number, correct_words):\n",
        "    words_in_sentence = sentence.split()\n",
        "    misspelled_words = []\n",
        "    corrected_words = []\n",
        "\n",
        "    # Process each word in the sentence\n",
        "    for word in words_in_sentence:\n",
        "        corrected_word = auto_correct(word, correct_words)\n",
        "        corrected_words.append(corrected_word)\n",
        "        if corrected_word != word:  # If the word is corrected\n",
        "            misspelled_words.append(word)\n",
        "\n",
        "    # Display the output\n",
        "    print(f\"Sample Sentence {sample_number}:\")\n",
        "    print(f\"Original Sentence: {sentence}\")\n",
        "    print(f\"Misspelled Words: {misspelled_words}\")\n",
        "    print(f\"Corrected Sentence: {' '.join(corrected_words)}\\n\")\n",
        "\n",
        "# Test the function with multiple sentences\n",
        "correct_words = [word for word, label in zip(words, labels) if label == 1]\n",
        "sentences = [\n",
        "    \"අම්මා යුහුෂුලුව අවදිවෙනවා\",\n",
        "    \"උකුෂ්ෂා සාර්ථඛව සුනඛයකු පස්සේ එළවනවා\",\n",
        "    \"සමකාළීන වෙඩික්කාරයා වෙඩිතියනවා\",\n",
        "    \"මුරඛාරයා සැළකිළිමත්ව වීදිය පසුකරනවා\",\n",
        "    \"ණාවිකයා සම්මත තාක්සණය නෞඛා පැදවීමට භාවිතා කරනවා\",\n",
        "]\n",
        "\n",
        "for i, sentence in enumerate(sentences, start=1):\n",
        "    process_sentence(sentence, sample_number=i, correct_words=correct_words)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
